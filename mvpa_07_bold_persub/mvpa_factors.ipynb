{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # MVPA Per Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "root_dir = '/Volumes/T7/BIDS-BRAINPLAYBACK-TASK2'\n",
    "fmriprep_dir = os.path.join(root_dir, 'derivatives', 'fmriprep23')\n",
    "dataset_dir  = os.path.join(root_dir, 'derivatives', 'mvpa_05_factors_bold', 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list datasets and concatenate\n",
    "\n",
    "# find all *_dataset.nii.gz files in dataset_dir\n",
    "dataset_files = [os.path.join(dataset_dir, f) for f in os.listdir(dataset_dir) if f.endswith('_features.npy') & f.startswith('sub-')]\n",
    "dataset_files.sort()\n",
    "\n",
    "# find all *_trial_types.txt files in dataset_dir\n",
    "label_files = [os.path.join(dataset_dir, f) for f in os.listdir(dataset_dir) if f.endswith('_labels.npy') & f.startswith('sub-')]\n",
    "label_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects found: 17.000000\n"
     ]
    }
   ],
   "source": [
    "# get number of subjects\n",
    "n_runs_per_sub = 4\n",
    "n_subjects = len(dataset_files) / n_runs_per_sub\n",
    "print('Number of subjects found: %f' % n_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of rows: 4896.0\n"
     ]
    }
   ],
   "source": [
    "# estimate expected number of rows\n",
    "# 17 subjects, 8 noise and 9 x 2 music for each of the 4 runs\n",
    "\n",
    "n_noise_trials = 0\n",
    "n_noise_splits = 0\n",
    "n_music_trials = 9*2\n",
    "n_music_splits = 4\n",
    "\n",
    "n_rows_estimate_per_run = n_noise_trials*n_noise_splits + n_music_trials*n_music_splits\n",
    "n_rows_estimate_per_sub = n_runs_per_sub * n_rows_estimate_per_run\n",
    "n_rows_estimate = n_subjects * n_rows_estimate_per_sub\n",
    "print(f'Estimated number of rows: {n_rows_estimate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate an array of chunk labels\n",
    "chunks = np.repeat(np.arange(1,n_runs_per_sub+1), n_rows_estimate_per_run)\n",
    "chunks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 1/17...subject 2/17...\n",
      "Selection from 4 to 8\n",
      "\n",
      "Selection from 0 to 4\n",
      "subject 3/17...\n",
      "Selection from 8 to 12\n",
      "subject 4/17...\n",
      "Selection from 12 to 16\n",
      "fold 1/4...\n",
      "fold 1/4...\n",
      "fold 1/4...\n",
      "fold 1/4...\n",
      "fold 2/4...\n",
      "fold 2/4...\n",
      "fold 2/4...\n",
      "fold 2/4...\n",
      "fold 3/4...\n",
      "fold 3/4...\n",
      "fold 3/4...\n",
      "fold 4/4...\n",
      "fold 3/4...\n",
      "fold 4/4...\n",
      "fold 4/4...\n",
      "subject 5/17...\n",
      "Selection from 16 to 20\n",
      "subject 6/17...\n",
      "Selection from 20 to 24\n",
      "fold 1/4...\n",
      "fold 4/4...\n",
      "fold 1/4...\n",
      "subject 7/17...\n",
      "Selection from 24 to 28\n",
      "fold 1/4...\n",
      "fold 2/4...\n",
      "fold 2/4...\n",
      "subject 8/17...\n",
      "Selection from 28 to 32\n",
      "fold 1/4...\n",
      "fold 3/4...\n",
      "fold 3/4...\n",
      "fold 2/4...\n",
      "fold 2/4...\n",
      "fold 4/4...\n",
      "fold 4/4...\n",
      "fold 3/4...\n",
      "subject 9/17...\n",
      "Selection from 32 to 36\n",
      "fold 3/4...\n",
      "fold 1/4...\n",
      "subject 10/17...\n",
      "Selection from 36 to 40\n",
      "fold 1/4...\n",
      "fold 4/4...\n",
      "fold 4/4...\n",
      "subject 11/17...\n",
      "Selection from 40 to 44\n",
      "fold 1/4...\n",
      "fold 2/4...\n",
      "fold 2/4...\n",
      "subject 12/17...\n",
      "Selection from 44 to 48\n",
      "fold 1/4...\n",
      "fold 3/4...\n",
      "fold 2/4...\n",
      "fold 3/4...\n",
      "fold 2/4...\n",
      "fold 4/4...\n",
      "fold 3/4...\n",
      "fold 3/4...\n",
      "fold 4/4...\n",
      "fold 4/4...\n",
      "subject 13/17...\n",
      "Selection from 48 to 52\n",
      "fold 1/4...\n",
      "fold 4/4...\n",
      "subject 14/17...\n",
      "Selection from 52 to 56\n",
      "fold 1/4...\n",
      "fold 2/4...\n",
      "subject 15/17...\n",
      "Selection from 56 to 60\n",
      "subject 16/17...\n",
      "Selection from 60 to 64\n",
      "fold 1/4...\n",
      "fold 1/4...\n",
      "fold 2/4...\n",
      "fold 3/4...\n",
      "fold 2/4...\n",
      "fold 2/4...\n",
      "fold 3/4...\n",
      "fold 4/4...\n",
      "fold 3/4...\n",
      "fold 3/4...\n",
      "subject 17/17...\n",
      "Selection from 64 to 68\n",
      "fold 4/4...\n",
      "fold 4/4...\n",
      "fold 1/4...\n",
      "fold 4/4...\n",
      "fold 2/4...\n",
      "fold 3/4...\n",
      "fold 4/4...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "n_classes = 3\n",
    "n_folds = int(n_runs_per_sub)\n",
    "n_subjects = int(n_subjects)\n",
    "acc_array = np.zeros((n_subjects,n_folds))\n",
    "acc_bal_array = np.zeros((n_subjects,n_folds))\n",
    "confusion_matrix_array = np.zeros((n_subjects,n_classes,n_classes,n_folds))\n",
    "\n",
    "def process_fold(ss):\n",
    "    print(f'subject {ss+1}/{n_subjects}...')\n",
    "\n",
    "    start_idx = (ss+1-1)*n_runs_per_sub\n",
    "    end_idx = n_runs_per_sub*(ss+1)\n",
    "    print(f'Selection from {start_idx} to {end_idx}')\n",
    "\n",
    "    samples = np.concatenate([np.load(f) for f in dataset_files[start_idx:end_idx]], axis=0)\n",
    "    labels = np.concatenate([np.load(f, allow_pickle=True) for f in label_files[start_idx:end_idx]], axis=0)\n",
    "\n",
    "    acc = np.zeros(n_folds)\n",
    "    acc_bal = np.zeros(n_folds)\n",
    "    cm = np.zeros((n_classes,n_classes,n_folds))\n",
    "\n",
    "    for ff in range(n_folds):\n",
    "        print(f'fold {ff+1}/{n_folds}...')\n",
    "\n",
    "        clf = LinearSVC(multi_class=\"ovr\", max_iter=5000, class_weight='balanced', dual='auto')\n",
    "        \n",
    "        # split the data into training and test set\n",
    "        train_mask = chunks != ff+1\n",
    "        test_mask = chunks == ff+1\n",
    "\n",
    "        X_train = samples[train_mask, :]\n",
    "        y_train = labels[train_mask]\n",
    "        X_test = samples[test_mask, :]\n",
    "        y_test = labels[test_mask]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # Compute the prediction accuracy for the different labels\n",
    "        acc[ff] = (y_pred == y_test).mean()\n",
    "        acc_bal[ff] = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # confusion matrix\n",
    "        cm[...,ff] = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return ss, acc, acc_bal, cm\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    results = list(executor.map(process_fold, range(int(n_subjects))))\n",
    "\n",
    "# Update the accuracy arrays with the results\n",
    "for ss, acc, acc_bal, cm in results:\n",
    "    acc_array[ss,:] = acc\n",
    "    acc_bal_array[ss,:] = acc_bal\n",
    "    confusion_matrix_array[ss,...] = cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_s = np.mean(np.mean(acc_array,1))*100\n",
    "s_s = np.std(np.mean(acc_array,1))*100\n",
    "m_b_s = np.mean(np.mean(acc_bal_array,1))*100\n",
    "s_b_s = np.std(np.mean(acc_bal_array,1))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy across subs: 44.2% ± 3.2%\n",
      "Mean balanced accuracy across subs: 36.2% ± 3.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean accuracy across subs: {m_s:0.1f}% \\u00B1 {s_s:0.1f}%\")\n",
    "print(f\"Mean balanced accuracy across subs: {m_b_s:0.1f}% \\u00B1 {s_b_s:0.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainplayback_task02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
