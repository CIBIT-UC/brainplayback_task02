{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # MVPA Music vs. Noise LS-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import os\n",
    "from nilearn.input_data import NiftiMasker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "root_dir = '/Volumes/T7/BIDS-BRAINPLAYBACK-TASK2'\n",
    "fmriprep_dir = os.path.join(root_dir, 'derivatives', 'fmriprep23')\n",
    "dataset_dir  = os.path.join(root_dir, 'derivatives', 'mvpa_01_musicnoise')\n",
    "\n",
    "# brain masks\n",
    "#mask_brain_file = os.path.join(root_dir, 'derivatives', 'mni_icbm152_t1_tal_nlin_asym_09c_res-2_dilated.nii')\n",
    "mask_gm_file    = os.path.join(root_dir, 'derivatives', 'mni_icbm152_gm_tal_nlin_asym_09c_res-2_dilated.nii')\n",
    "\n",
    "# Numer of runs per participant\n",
    "nRunsPerSub = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list datasets and concatenate\n",
    "\n",
    "# find all *_dataset.nii.gz files in dataset_dir\n",
    "dataset_files = [os.path.join(dataset_dir, f) for f in os.listdir(dataset_dir) if f.endswith('_musicnoise_confounds_dataset.nii.gz') & f.startswith('sub-')]\n",
    "dataset_files.sort()\n",
    "\n",
    "# find all *_trial_types.txt files in dataset_dir\n",
    "label_files = [os.path.join(dataset_dir, f) for f in os.listdir(dataset_dir) if f.endswith('_musicnoise_confounds_trial_types.txt') & f.startswith('sub-')]\n",
    "label_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects found: 17.000000\n"
     ]
    }
   ],
   "source": [
    "# get number of subjects\n",
    "# if this is not an integer, something is wrong\n",
    "n_subjects = len(dataset_files) / nRunsPerSub\n",
    "print('Number of subjects found: %f' % n_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all datasets (estimated duration: 50 seconds)\n",
    "D = nb.concat_images(dataset_files, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all labels into a single string array\n",
    "labels = np.concatenate([np.loadtxt(l, dtype=str) for l in label_files])\n",
    "\n",
    "# trim each label to remove the 2 digit number in the end\n",
    "labels = np.array([l[:-2] for l in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load masker\n",
    "masker = NiftiMasker(mask_img=mask_gm_file, standardize=False, detrend=False)\n",
    "\n",
    "# Extract data from mask (estimated duration: 2.5 minutes)\n",
    "samples = masker.fit_transform(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate an array of chunk labels\n",
    "# 17 subjects, 10 noise and 9 x 2 music for each of the 4 runs\n",
    "chunks = np.repeat(np.arange(1,n_subjects+1), 10*4 + 9*2*nRunsPerSub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's specify the classifier\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(multi_class=\"ovr\", max_iter=2000, class_weight='balanced', dual='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Leave One Subject Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimated duration: 10 minutes\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "n_folds = int(n_subjects)\n",
    "acc_array = np.zeros(n_folds)\n",
    "acc_bal_array = np.zeros(n_folds)\n",
    "\n",
    "fig, ax = plt.subplots(math.ceil(n_folds/2), 2, figsize=(8, n_folds))\n",
    "\n",
    "for ff in range(n_folds):\n",
    "    print(f'fold {ff}/{n_folds}...')\n",
    "\n",
    "    # split the data into training and test set\n",
    "    train_mask = chunks != ff+1\n",
    "    test_mask = chunks == ff+1\n",
    "\n",
    "    X_train = samples[train_mask, :]\n",
    "    y_train = labels[train_mask]\n",
    "    X_test = samples[test_mask, :]\n",
    "    y_test = labels[test_mask]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Compute the prediction accuracy for the different labels\n",
    "    acc_array[ff] = (y_pred == y_test).mean()\n",
    "    acc_bal_array[ff] = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Confusion matrix plots\n",
    "    ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test, ax=ax[ff // 2, ff % 2])\n",
    "    ax[ff // 2, ff % 2].set_title(f\"Fold {ff}, bal acc: {acc_bal_array[ff]*100:0.1f}%\")\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 86.6% ± 5.3%\n",
      "Mean balanced accuracy: 83.2% ± 6.3%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean accuracy: {acc_array.mean()*100:0.1f}% \\u00B1 {acc_array.std()*100:0.1f}%\")\n",
    "print(f\"Mean balanced accuracy: {acc_bal_array.mean()*100:0.1f}% \\u00B1 {acc_bal_array.std()*100:0.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize weights in the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nilearn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NiftiMasker.fit] Loading data from None\n",
      "[NiftiMasker.fit] Resampling mask\n",
      "[NiftiMasker.fit] Finished fit\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(\n",
      "shape=(97, 115, 97, 1904),\n",
      "affine=array([[   2. ,    0. ,    0. ,  -96.5],\n",
      "       [   0. ,    2. ,    0. , -132.5],\n",
      "       [   0. ,    0. ,    2. ,  -78.5],\n",
      "       [   0. ,    0. ,    0. ,    1. ]])\n",
      ")\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "/opt/anaconda3/envs/brainplayback_task02/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [    0     4     5     6    74  6102  6104  6382  6387  6388  6393  6394\n",
      "  6408  6417  6705  6714  6715  6716  6723  6724  6725  6726  6732  6733\n",
      "  6734  6740  6746  6747  6753  6754  7092  7104  7105  7114  7490  7875\n",
      "  8360  8892 17553 17580 18184 18207 18208 18231 18864 18879 18880 19291\n",
      " 19300 19301 19302 19313 19314 19315 19323 19327 19330 19648 19653 19654\n",
      " 19655 19657 19936 24654 25112 25204 25223 25232 25333 25334 25335 25346\n",
      " 25347 25449 25450 25451 25452 25453 25456 25516 25517 25518 25519 25533\n",
      " 25534 25535 25536] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/opt/anaconda3/envs/brainplayback_task02/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [    0     4     5     6    74   127  6102  6104  6382  6387  6388  6393\n",
      "  6394  6408  6417  6705  6714  6715  6716  6723  6724  6725  6726  6732\n",
      "  6733  6734  6740  6746  6747  6753  6754  7092  7104  7105  7114  7490\n",
      "  7875  8360  8892 16964 17553 17580 18184 18207 18208 18231 18864 18879\n",
      " 18880 19291 19300 19301 19302 19313 19314 19315 19323 19327 19330 19648\n",
      " 19653 19654 19657 24654 25112 25204 25223 25232 25333 25334 25335 25346\n",
      " 25347 25449 25450 25451 25452 25453 25456 25515 25516 25517 25518 25519\n",
      " 25533 25534 25535 25536] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/opt/anaconda3/envs/brainplayback_task02/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/opt/anaconda3/envs/brainplayback_task02/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/opt/anaconda3/envs/brainplayback_task02/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [    0     4     5     6    74  6102  6104  6382  6387  6388  6393  6394\n",
      "  6408  6417  6705  6714  6715  6716  6723  6724  6725  6726  6732  6733\n",
      "  6734  6740  6746  6747  6753  6754  7092  7104  7105  7114  7490  7875\n",
      "  8360  8892 17553 17580 18184 18207 18208 18231 18864 18879 18880 19291\n",
      " 19300 19301 19302 19313 19314 19315 19323 19327 19330 19648 19653 19654\n",
      " 19657 24654 25112 25204 25223 25232 25333 25334 25335 25346 25347 25449\n",
      " 25450 25451 25452 25453 25456 25516 25517 25518 25519 25533 25534 25535\n",
      " 25536] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/opt/anaconda3/envs/brainplayback_task02/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/opt/anaconda3/envs/brainplayback_task02/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [    0     4     5     6    74   815   816   976   979  1175  1180  6102\n",
      "  6104  6382  6387  6388  6393  6394  6401  6408  6417  6705  6714  6715\n",
      "  6716  6723  6724  6725  6726  6732  6733  6734  6740  6746  6747  6753\n",
      "  6754  7092  7104  7105  7114  7490  7875  7892  8360  8375  8892  8907\n",
      " 17553 17580 18184 18207 18208 18231 18864 18879 18880 19291 19300 19301\n",
      " 19302 19313 19314 19315 19323 19327 19330 19648 19653 19654 19657 24654\n",
      " 24792 25110 25111 25112 25204 25223 25232 25333 25334 25335 25346 25347\n",
      " 25348 25349 25449 25450 25451 25452 25453 25456 25516 25517 25518 25519\n",
      " 25530 25531 25532 25533 25534 25535 25536] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/opt/anaconda3/envs/brainplayback_task02/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/opt/anaconda3/envs/brainplayback_task02/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [    0     4     5     6    74  6102  6104  6382  6387  6388  6393  6394\n",
      "  6408  6417  6705  6714  6715  6716  6723  6724  6725  6726  6732  6733\n",
      "  6734  6740  6746  6747  6753  6754  6973  7092  7104  7105  7114  7490\n",
      "  7759  7760  7781  7801  7875  8234  8360  8892 17553 17580 18184 18207\n",
      " 18208 18231 18864 18879 18880 19291 19300 19301 19302 19313 19314 19315\n",
      " 19323 19327 19330 19648 19653 19654 19657 24654 25112 25204 25223 25232\n",
      " 25333 25334 25335 25346 25347 25449 25450 25451 25452 25453 25456 25458\n",
      " 25516 25517 25518 25519 25533 25534 25535 25536] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/opt/anaconda3/envs/brainplayback_task02/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/opt/anaconda3/envs/brainplayback_task02/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [    0     4     5     6    73    74   185  6102  6104  6382  6387  6388\n",
      "  6393  6394  6408  6417  6705  6714  6715  6716  6723  6724  6725  6726\n",
      "  6732  6733  6734  6740  6746  6747  6753  6754  7092  7104  7105  7106\n",
      "  7114  7115  7425  7490  7875  8360  8892 17553 17580 18184 18207 18208\n",
      " 18231 18255 18830 18864 18879 18880 19291 19300 19301 19302 19313 19314\n",
      " 19315 19316 19323 19324 19327 19330 19648 19653 19654 19657 24654 25112\n",
      " 25203 25204 25223 25232 25333 25334 25335 25346 25347 25449 25450 25451\n",
      " 25452 25453 25456 25457 25510 25516 25517 25518 25519 25533 25534 25535\n",
      " 25536] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/opt/anaconda3/envs/brainplayback_task02/lib/python3.11/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LeaveOneGroupOut\n\u001b[1;32m      4\u001b[0m decoder \u001b[38;5;241m=\u001b[39m Decoder(\n\u001b[1;32m      5\u001b[0m     estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask_gm_file,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(decoder\u001b[38;5;241m.\u001b[39mcv_params_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMusic\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/brainplayback_task02/lib/python3.11/site-packages/nilearn/decoding/decoder.py:770\u001b[0m, in \u001b[0;36m_BaseDecoder.fit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    760\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    761\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter clustering and screening, the decoding model will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    762\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe trained only on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_final_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    766\u001b[0m     )\n\u001b[1;32m    768\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m--> 770\u001b[0m parallel_fit_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_fit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_classification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_classification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mselector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_img\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_img_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclustering_percentile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclustering_percentile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_problems\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m coefs, intercepts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_parallel_fit_outputs(\n\u001b[1;32m    791\u001b[0m     parallel_fit_outputs, y, n_problems\n\u001b[1;32m    792\u001b[0m )\n\u001b[1;32m    794\u001b[0m \u001b[38;5;66;03m# Build the final model (the aggregated one)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/brainplayback_task02/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/brainplayback_task02/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/brainplayback_task02/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from nilearn.decoding import Decoder\n",
    "#from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "decoder = Decoder(\n",
    "    estimator=\"svc\",\n",
    "    mask=mask_gm_file,\n",
    "    standardize=False,\n",
    "    cv=17,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=6,\n",
    "    verbose=1,\n",
    ")\n",
    "decoder.fit(D, labels)\n",
    "\n",
    "print(decoder.cv_params_[\"Music\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "plotting.view_img(\n",
    "    decoder.coef_img_[\"Music\"],\n",
    "    title=\"SVM weights\",\n",
    "    dim=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_decoder = Decoder(\n",
    "    estimator=\"dummy_classifier\",\n",
    "    mask=mask_filename,\n",
    "    groups=chunks,\n",
    "    cv=LeaveOneGroupOut()\n",
    "    standardize=\"zscore_sample\",\n",
    ")\n",
    "dummy_decoder.fit(fmri_niimgs, conditions, groups=run_label)\n",
    "\n",
    "# Now, we can compare these scores by simply taking a mean over folds\n",
    "print(dummy_decoder.cv_scores_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainplayback_task02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
