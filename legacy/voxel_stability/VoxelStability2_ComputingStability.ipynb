{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e4876c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn import over_sampling \n",
    "\n",
    "from itertools import combinations\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "from src.data_balancing import data_balancing\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "439c090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DATA =r'C:\\Users\\anaga\\OneDrive\\Universidade\\5º ano\\Tese'\n",
    "SES='ses-01'\n",
    "TASK = 'task-01'\n",
    "TR = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44365d5",
   "metadata": {},
   "source": [
    "#### Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2f693ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB = 'sub-04'\n",
    "\n",
    "labels_type = 'ptcps' #'predef' (predefined labels) or 'ptcps' (participant's labels)\n",
    "\n",
    "file_name_format = SUB + '_' + SES + '_' + TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23ad8fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if labels_type == 'ptcps': \n",
    "\n",
    "    # data folder\n",
    "    results_path = os.path.join(ROOT_DATA, 'results','voxel_stability','participant_labels')\n",
    "\n",
    "elif labels_type == 'predef':\n",
    "    results_path = os.path.join(ROOT_DATA, 'results','voxel_stability','predefined_labels')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae00254",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8fdb92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of events_not_balanced df:  128\n",
      "Image 2D not balanced shape: 2d   (128, 1082035)\n",
      "Image 4D not balanced shape: 4d   (97, 115, 97, 128)\n"
     ]
    }
   ],
   "source": [
    "# Image with all runs of a participant not balanced\n",
    "imgs_not_balanced_fn = os.path.join(results_path,SUB, file_name_format +'_allruns_VS.nii.gz')\n",
    "\n",
    "# 4D image\n",
    "imgs_not_balanced = nib.load(imgs_not_balanced_fn)\n",
    "\n",
    "# Image signal data\n",
    "data_not_balanced = imgs_not_balanced.get_fdata()\n",
    "\n",
    "# Number of voxels\n",
    "n_voxels = np.prod(data_not_balanced.shape[:3])\n",
    "\n",
    "# Number of volumes\n",
    "n_vols = data_not_balanced.shape[3]\n",
    "\n",
    "#Convert 4D image to 2D image\n",
    "data_notbalanced_2d = np.reshape(data_not_balanced, (n_voxels, n_vols))\n",
    "data_notbalanced_2d = np.transpose(data_notbalanced_2d)\n",
    "\n",
    "\n",
    "# Events dataframe with all runs of a participant not balanced\n",
    "events_not_balanced_fn = os.path.join(results_path,SUB,file_name_format + '_events_all_runs_VS.csv')\n",
    "\n",
    "# Read events dataframe\n",
    "events_not_balanced=pd.read_csv(events_not_balanced_fn,sep=';',index_col = 0)\n",
    "\n",
    "print('Length of events_not_balanced df: ',len(events_not_balanced))\n",
    "print('Image 2D not balanced shape: 2d  ',data_notbalanced_2d.shape)\n",
    "print('Image 4D not balanced shape: 4d  ',imgs_not_balanced.shape)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a2a7d8c",
   "metadata": {},
   "source": [
    "### Create training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac327c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train, img_test, events_train, events_test = train_test_split(data_notbalanced_2d, events_not_balanced, stratify = events_not_balanced['trial_type'],test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eaaa3cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Noise    22\n",
       "Q4       21\n",
       "Q2       19\n",
       "Q1       19\n",
       "Q3        8\n",
       "Name: trial_type, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_train['trial_type'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bb57e71",
   "metadata": {},
   "source": [
    " ### Oversampling the training data or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb0fcdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if labels_type == 'ptcps':\n",
    "\n",
    "    # get the name and the counts of the label with minimum counts in the training set\n",
    "    min_label = events_train['trial_type'].value_counts().idxmin()\n",
    "    min_count = events_train['trial_type'].value_counts().min()\n",
    "\n",
    "    # oversample the label with minimum counts in the training set\n",
    "    oversample = over_sampling.SMOTE(sampling_strategy = {min_label: 12}, k_neighbors=min_count-1)\n",
    "\n",
    "    if min_count>=12:\n",
    "        X_resampled, y_resampled = img_train,events_train['trial_type'].values\n",
    "        \n",
    "    else:\n",
    "        # fit resample \n",
    "        X_resampled, y_resampled = oversample.fit_resample(img_train,events_train['trial_type'])\n",
    "\n",
    "\n",
    "        # Turn y_resampled into a dataframe\n",
    "        y_resampled_df = pd.DataFrame(y_resampled, columns = ['trial_type'])\n",
    "\n",
    "        # If there is more than one label with less than 12 counts:\n",
    "\n",
    "        # get the name and the counts of the label with minimum counts in the training set\n",
    "        second_min_label = y_resampled_df['trial_type'].value_counts().idxmin()\n",
    "        second_min_count = y_resampled_df['trial_type'].value_counts().min()\n",
    "\n",
    "        if second_min_count < 12:\n",
    "            # oversample the label with minimum counts in the training set\n",
    "            oversample = over_sampling.SMOTE(sampling_strategy = {second_min_label: 12}, k_neighbors=second_min_count-1)\n",
    "\n",
    "            # fit resample \n",
    "            X_resampled, y_resampled = oversample.fit_resample(X_resampled,y_resampled_df['trial_type'])\n",
    "\n",
    "\n",
    "    # Turn y_resampled into a dataframe\n",
    "    y_resampled_df = pd.DataFrame(y_resampled, columns = ['trial_type'])\n",
    "\n",
    "    # Convert the 2d image back to 4d\n",
    "    n_vols = X_resampled.shape[0]\n",
    "    shape = list(data_not_balanced.shape[0:3])\n",
    "\n",
    "    #Add the number of volumes to the shape\n",
    "    shape.append(n_vols)\n",
    "\n",
    "    # Convert X_resampled to 4d\n",
    "    X_resampled_4d = np.reshape(X_resampled, shape)\n",
    "\n",
    "    resampled_nii_img = nib.Nifti1Image(X_resampled_4d, imgs_not_balanced.affine, imgs_not_balanced.header)\n",
    "\n",
    "\n",
    "    img_4d_fn = SUB + '_' + SES + '_' + TASK +'_allruns_train_VS.nii.gz'\n",
    "    nib.save(resampled_nii_img, f'{results_path}/{img_4d_fn}')\n",
    "\n",
    "    X_train = X_resampled\n",
    "    y_train = y_resampled_df\n",
    "\n",
    "else:\n",
    "    y_train = events_train['trial_type']\n",
    "    X_train = img_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a908b375",
   "metadata": {},
   "source": [
    "### Balance training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bd20f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_train_balanced shape (60, 1082035)\n",
      "events_train_balanced length:  60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Q2       12\n",
       "Noise    12\n",
       "Q1       12\n",
       "Q4       12\n",
       "Q3       12\n",
       "Name: trial_type, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# allruns='no' para não fazer o balanceamento dentro de cada run\n",
    "img_train_balanced,events_train_balanced = data_balancing(X_train,y_train,'no','no')\n",
    "\n",
    "\n",
    "print('img_train_balanced shape', img_train_balanced.shape)\n",
    "print('events_train_balanced length: ',len(events_train_balanced))\n",
    "\n",
    "events_train_balanced['trial_type'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c29bb63",
   "metadata": {},
   "source": [
    "#### Save train and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7ec148",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_train_fn = os.path.join(results_path,file_name_format+'events_train.csv')\n",
    "events_train_balanced.to_csv(events_train_fn,sep=';')\n",
    "\n",
    "events_test_fn = os.path.join(results_path,file_name_format+'events_test.csv')\n",
    "events_test.to_csv(events_test_fn,sep=';')\n",
    "\n",
    "img_train_fn = os.path.join(results_path,file_name_format+'img_data_train.npy')\n",
    "np.save(img_train_fn,img_train_balanced)\n",
    "\n",
    "img_test_fn = os.path.join(results_path,file_name_format+'img_data_test.npy')\n",
    "np.save(img_test_fn,img_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9ee4b9e",
   "metadata": {},
   "source": [
    "\n",
    "### Organize the signal values of each voxel in each Noise, Q1,Q2,Q3,Q4 block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a257d536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>trial_type</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>...</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082030</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082031</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082032</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082033</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082034</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1082035 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "trial_type  Noise   Q1   Q2   Q3   Q4  Noise   Q1   Q2   Q3   Q4  ...  Noise  \\\n",
       "0             0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "1             0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "2             0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "3             0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "4             0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "...           ...  ...  ...  ...  ...    ...  ...  ...  ...  ...  ...    ...   \n",
       "1082030       0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "1082031       0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "1082032       0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "1082033       0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "1082034       0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "\n",
       "trial_type   Q1   Q2   Q3   Q4  Noise   Q1   Q2   Q3   Q4  \n",
       "0           0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  \n",
       "1           0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  \n",
       "2           0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  \n",
       "3           0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  \n",
       "4           0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  \n",
       "...         ...  ...  ...  ...    ...  ...  ...  ...  ...  \n",
       "1082030     0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  \n",
       "1082031     0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  \n",
       "1082032     0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  \n",
       "1082033     0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  \n",
       "1082034     0.0  0.0  0.0  0.0    0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[1082035 rows x 60 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reorg_df = events_train_balanced.copy()\n",
    "\n",
    "# Group by trial_type and create a new column with the order of each value within its group\n",
    "reorg_df['order'] = reorg_df.groupby('trial_type').cumcount()\n",
    "\n",
    "# Sort by the order column to reorder the rows within each group\n",
    "reorg_df = reorg_df.sort_values(['order', 'trial_type'])\n",
    "\n",
    "reorg_df.drop('order', axis=1, inplace=True)\n",
    "\n",
    "#Indexes da tabela original na ordem que corresponde à ordenação dos trial_types (para ordenar o sinal dos voxeis)\n",
    "reorg_indexes = reorg_df.index\n",
    "\n",
    "#Reordenar o array 2d com o sinal de todos os voxeis para corresponder à nova ordem da data frame\n",
    "reorg_2d_data = np.transpose(img_train_balanced[reorg_indexes,:])\n",
    "\n",
    "# Colunas da nova dataframe são os trial_types reorganizados \n",
    "trial_types = reorg_df['trial_type']\n",
    "# Criar uma dataframe com o sinal de todos os voxeis\n",
    "voxels_df = pd.DataFrame(data=reorg_2d_data, columns=trial_types)\n",
    "voxels_df\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa7d1c55",
   "metadata": {},
   "source": [
    "### Calculates stability of each voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init timer()\n",
    "fit_start=timer()\n",
    "\n",
    "#Creates a new sub-dataframe for each voxel in which each row corresponds to a block of stimuli\n",
    "\n",
    "set_size = 5 #Set size ['Noise', 'Q1','Q2','Q3','Q4']\n",
    "\n",
    "#Number of sets of 5 blocks\n",
    "sets_number = int((voxels_df.shape[1] / set_size))\n",
    "sets_number\n",
    "\n",
    "voxels_stability = []\n",
    "\n",
    "for voxel in range(len(voxels_df)):\n",
    "#for voxel in range(0,1):\n",
    "\n",
    "    voxel_sets = []\n",
    "\n",
    "    # Separates the dataframe into dataframes corresponding to each trial (presentation set) to reorganize the data\n",
    "    for i in range(0,voxels_df.shape[1] , set_size):\n",
    "        df_trial = voxels_df.iloc[voxel, i:i+set_size]\n",
    "        voxel_sets.append(df_trial)\n",
    "\n",
    "\n",
    "    voxel_all_sets = pd.concat(voxel_sets)\n",
    "    voxel_all_sets_df  = pd.DataFrame(np.array(voxel_all_sets).reshape(sets_number,5))\n",
    "\n",
    "    # Assign column names\n",
    "    voxel_all_sets_df.columns = ['Noise', 'Q1', 'Q2', 'Q3', 'Q4']\n",
    "    #display(voxel_all_sets_df)\n",
    "\n",
    "\n",
    "    # Determines all possible combinations between each stimulus block (there are 8 blocks -> 8 choose 2 = 28 combinations)\n",
    "    combs = list(combinations(voxel_all_sets_df.index, 2))\n",
    "    #print('len combs: ',len(combs))\n",
    "\n",
    "    #Pairwise correlations between the responses of each voxel\n",
    "    voxel_corr = []\n",
    "    for i, j in combs:\n",
    "        #Pairwise correlations between the presentation sets\n",
    "        corr = np.corrcoef(voxel_all_sets_df.iloc[i], voxel_all_sets_df.iloc[j])[0,1]\n",
    "        voxel_corr.append(corr)\n",
    "\n",
    "    #The stability of a voxel is the average of the pairwise correlations between the possible combinations of blocks\n",
    "    voxel_stability = np.mean(voxel_corr)\n",
    "    voxels_stability.append(voxel_stability)\n",
    "\n",
    "    #Print stability from 10000 to 10000 voxels\n",
    "    if (voxel) % 10000 == 0:\n",
    "        print('Voxel {} stability: {:.6f} '.format(voxel+1,voxel_stability))\n",
    "    #print('Voxel {} stability: {:.6f} '.format(voxel+1,voxel_stability))\n",
    "\n",
    "# stop timer()\n",
    "fit_end=timer()\n",
    "\n",
    "# print elapsed time for model training\n",
    "print(timedelta(seconds=fit_end-fit_start))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a75c990f",
   "metadata": {},
   "source": [
    "####  Saves dataframe with stability of all voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc138c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with the stabolity of each voxel\n",
    "all_voxels_stability = pd.DataFrame({'voxel': range(len(voxels_df)),'stability': voxels_stability})\n",
    "\n",
    "#Save dataframe with all voxels stability\n",
    "all_voxels_fn = os.path.join(results_path,SUB,file_name_format+'_stability_all_voxels.csv')\n",
    "all_voxels_stability.to_csv(all_voxels_fn,sep=';')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "272b36ac",
   "metadata": {},
   "source": [
    "#### Saves dataframe with the stability of the n most stable voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a49544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load of the dataframe with the stability of all voxels\n",
    "all_voxels_stability_fn = os.path.join(results_path,SUB,file_name_format+'_stability_all_voxels.csv')\n",
    "all_voxels_stability = pd.read_csv(all_voxels_stability_fn,sep=';',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a648857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvoxels_list = np.array(range(100,1100,100))\n",
    "nvoxels_list = [100,200,300,400,500,600,700,800,900,1000,5000,10000,100000,900000]\n",
    "\n",
    "\n",
    "#Selects the n most stable voxels\n",
    "for n in nvoxels_list:\n",
    "    top_voxels = all_voxels_stability.nlargest(n, 'stability')\n",
    "    most_stable_voxels = top_voxels.reset_index(drop=True)\n",
    "\n",
    "    #Saves the dataframe with the stability and the indexes of the most stable voxels\n",
    "    most_stable_voxels_fn = os.path.join(results_path,SUB,file_name_format+'_'+str(n)+'_most_stable_voxels.csv')\n",
    "    most_stable_voxels.to_csv(most_stable_voxels_fn,sep=';')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f42ba091",
   "metadata": {},
   "source": [
    "### Creating mask with most n stable voxels\n",
    "#### Apply mask to test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781914c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in nvoxels_list:\n",
    "    \n",
    "    print('n: ',n)\n",
    "    \n",
    "    #Load and setting the indexes of the most stable voxels to a numpy array\n",
    "    most_stable_voxels_fn = os.path.join(results_path,SUB,file_name_format+'_'+str(n)+'_most_stable_voxels.csv')\n",
    "    most_stable_voxels = np.array(pd.read_csv(most_stable_voxels_fn,sep=';',index_col=0)['voxel'])\n",
    "    print('stable_voxels.shape: ',most_stable_voxels.shape)\n",
    "\n",
    "    #Load of the training set\n",
    "    img_train_fn = os.path.join(results_path,SUB,file_name_format+'img_data_train.npy')\n",
    "    img_train = np.load(img_train_fn)\n",
    "    print('img_train shape:',img_train.shape)\n",
    "\n",
    "    #Load of the testing set\n",
    "    img_test_fn = os.path.join(results_path,SUB,file_name_format+'img_data_test.npy')\n",
    "    img_test = np.load(img_test_fn)\n",
    "    print('img_test shape:',img_test.shape)\n",
    "\n",
    "    #Masked test set\n",
    "    masked_test_set = img_test[:,most_stable_voxels]\n",
    "    print('masked_test_set shape:',masked_test_set.shape)\n",
    "\n",
    "    #Masked training set\n",
    "    masked_training_set = img_train[:,most_stable_voxels]\n",
    "    print('masked_training_set shape:',masked_training_set.shape)\n",
    "    \n",
    "    #Save masked training set only with stable voxels\n",
    "    masked_train_fn = os.path.join(results_path,SUB,file_name_format+'_'+str(n)+'voxels_train_set.npy')\n",
    "    np.save(masked_train_fn, masked_training_set)\n",
    "    \n",
    "    #Save test testing set only with stable voxels\n",
    "    masked_test_fn = os.path.join(results_path,SUB,file_name_format+'_'+str(n)+'voxels_test_set.npy')\n",
    "    np.save(masked_test_fn, masked_test_set)\n",
    "    \n",
    "    #Load of the 4D image with all voxels\n",
    "    img_all_voxels = nib.load(imgs_not_balanced_fn)\n",
    "    print('imgs_all.shape: ',img_all_voxels.shape)\n",
    "    \n",
    "    \n",
    "    # Inicialize mask with 0's\n",
    "    mask_2d = np.zeros(data_notbalanced_2d.shape[1])\n",
    "\n",
    "    #The indexes that correspond to the stable voxels are set to 1\n",
    "    mask_2d[most_stable_voxels]=1\n",
    "    print('mask_2d.shape: ',mask_2d.shape)\n",
    "\n",
    "    # Image reshape from 2D to 3D\n",
    "    mask_3d = mask_2d.reshape(img_all_voxels.shape[:3])\n",
    "    print('mask_3d.shape: ',mask_3d.shape)\n",
    "\n",
    "    #New nifti image with the same header information as the original image\n",
    "    mask_img = nib.Nifti1Image(mask_3d, img_all_voxels.affine, img_all_voxels.header)\n",
    "    print('mask_img.shape: ',mask_img.shape)\n",
    "\n",
    "    #Save mask image with n voxels\n",
    "    mask_img_fn = file_name_format+'_'+str(n)+'voxels_img3D_VS.nii.gz'\n",
    "    nib.save(mask_img, f'{results_path}/{mask_img_fn}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
